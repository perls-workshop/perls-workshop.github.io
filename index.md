---
layout: default
---

# Overview

Sponsored by the Center for Human-Compatible AI at UC Berkeley, and with support from the Simons Institute and the Center for Long-Term Cybersecurity, we are convening a cross-disciplinary group of researchers to examine the near-term policy concerns of Reinforcement Learning (RL).
RL is a rapidly growing branch of AI research, with the capacity to learn to exploit our dynamic behavior in real time.
From YouTube’s recommendation algorithm to post-surgery opioid prescriptions, RL algorithms are poised to permeate our daily lives.
The ability of the RL system to tease out behavioral responses, and the human experimentation inherent to its learning, motivate a range of crucial policy questions about RL’s societal implications that are distinct from those addressed in the literature on other branches of Machine Learning (ML).

We began addressing these issues as part of the [2020 Simons Institute program on the Theory of Reinforcement Learning](https://simons.berkeley.edu/news/mapping-political-economy-reinforcement-learning-systems-case-autonomous-vehicles), and throughout 2020/21 we have been broadening the discussion through an [ongoing reading group](https://geesegraduates.org/2020/10/26/political-economy-of-reinforcement-learning/), including perspectives from Law and Policy.
The aim of this workshop will be to establish a common language around the state of the art of RL across key societal domains.
From this examination, we hope to identify specific interpretive gaps that can be elaborated or filled by members of our community.
Our ultimate goal will be to map near-term societal concerns and indicate possible cross-disciplinary avenues towards addressing them.

# How to participate

 * Register for workshop updates below
 * Check this site closer to NeurIPS for more updates

<iframe src="https://docs.google.com/forms/d/e/1FAIpQLSdSOu8dPtBHHG126JJ5ns3TFVj4c_bnZiZflOcmG31h9l55xQ/viewform?embedded=true" width="100%" height="600pt" frameborder="0" marginheight="0" marginwidth="0">Loading…</iframe>
