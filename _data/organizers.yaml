
# A list of organizers for the workshop
# The order here determines the order they appear on the page

 - name: Stuart Russell
   website: https://people.eecs.berkeley.edu/~russell/
   image: /assets/organizer-images/russell.jpg
   bio: >
    Stuart Russell is a Professor of Computer Science at the University of California at Berkeley, holder of the Smith-Zadeh Chair in Engineering, and Director of the Center for Human-Compatible AI.
    He is a recipient of the IJCAI Computers and Thought Award and from 2012 to 2014 held the Chaire Blaise Pascal in Paris.
    He is an Honorary Fellow of Wadham College, Oxford, an Andrew Carnegie Fellow, and a Fellow of the American Association for Artificial Intelligence, the Association for Computing Machinery, and the American Association for the Advancement of Science.
    His book "Artificial Intelligence: A Modern Approach" (with Peter Norvig) is the standard text in AI, used in 1500 universities in 135 countries.
    His research covers a wide range of topics in artificial intelligence, with an emphasis on the long-term future of artificial intelligence and its relation to humanity.
    He has developed a new global seismic monitoring system for the nuclear-test-ban treaty and is currently working to ban lethal autonomous weapons.

 - name: Thomas Krendl Gilbert
   website: https://www.thomaskrendlgilbert.com/
   image: /assets/organizer-images/gilbert.jpg
   bio: >
    ​Thomas Krendl Gilbert is an interdisciplinary Ph.D. candidate in Machine Ethics and Epistemology at UC Berkeley, supported by the Center for Human-Compatible AI, the Simons Institute, and the Center for Long-Term Cybersecurity.
    His interest in the societal implications of RL systems grows out of his affiliation with the Simons program on the Theory of Reinforcement Learning held during fall 2020.
    Tom’s research examines how to ensure that the objectives for which we are optimizing in RL are aligned with normative social, political, and economic goals, and how notions of fairness, justice, equality, and rule of law can be prioritized in the design of our objectives, and objective functions.
    Thomas’ recent work investigates how specific algorithmic learning procedures (such as RL) reframe classical ethical questions and recall the foundations of democratic political philosophy, namely the significance of popular sovereignty and dissent for resolving normative uncertainty and modeling human preferences.

 - name: Tom Zick
   website: https://cyber.harvard.edu/people/tom-zick
   image: /assets/organizer-images/zick.jpg
   bio: >
    Tom Zick earned her PhD from UC Berkeley and is currently pursuing her JD at Harvard.
    Her research bridges between AI ethics and law, with a focus on how to craft safe and equitable policy surrounding the adoption of AI in high-stakes domains.
    In the past, she has worked as a data scientist at the Berkeley Center for Law and Technology, evaluating the capacity of regulations to promote open government data.
    She has also collaborated with graduate students across social science and engineering to advocate for pedagogy reform focused on infusing social context into technical coursework.
    Outside of academia, Tom has crafted digital policy for the City of Boston as a fellow for the Mayor’s Office for New Urban Mechanics and helped early stage startups develop responsible AI frameworks.
    Her current research centers on the near term policy concerns surrounding reinforcement learning.
    
 - name: Aaron Snoswell
   website: https://aaronsnoswell.github.io/
   image: /assets/organizer-images/snoswell.jpg
   bio: >
    Aaron is a research fellow in computational law at the Australian Research Council Centre of Excellence for Autonomous Decision Making and Society.
    With a background in cross-disciplinary mechatronic engineering, Aaron’s Ph.D. research developed new theory and algorithms for Inverse Reinforcement Learning in the maximum conditional entropy and multiple intent settings.
    Aaron’s ongoing work investigates technical measures for achieving value alignment for autonomous decision making systems, and legal-theoretic models for AI accountability.

 - name: Michael Dennis
   website: https://scholar.google.com/citations?user=WXXu26AAAAAJ&hl=en&oi=sra
   image: /assets/organizer-images/dennis.jpg
   bio: >
    Michael Dennis is a 5th year grad student at the Center for Human-Compatible AI.
    With a background in theoretical computer science, he is working to close the gap between decision theoretic and game theoretic recommendations and the current state of the art approaches to robust RL and multi-agent RL.
    The overall aim of this work is to ensure that our systems behave in a way that is robustly beneficial.
    In the single agent setting, this means making decisions and managing risk in the way the designer intends.
    In the multi-agent setting, this means ensuring that the concerns of the designer and those of others in the society are fairly and justly negotiated to the benefit of all involved.
