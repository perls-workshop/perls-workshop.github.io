
@inproceedings{eschenbaum_robust_2021,
	title = {Robust Algorithmic Collusion},
	url = {https://openreview.net/forum?id=BztUFukcBry},
	abstract = {This paper develops an approach to assess reinforcement learners with collusive pricing policies in a testing environment. We find that algorithms are unable to extrapolate collusive policies from their training environment to testing environments. Collusion consistently breaks down, and algorithms instead tend to converge to Nash prices. Policy updating with or without exploration re-establishes collusion, but only in the current environment. This is robust to repeated learning across environments. Our results indicate that frequent market interaction, coordination of algorithm design, and stable environments are essential for algorithmic collusion.},
	eventtitle = {Neural Information Processing Systems},
	booktitle = {Workshop on the Political Economy of Reinforcement Learning Systems},
	author = {Eschenbaum, Nicolas and Zahn, Phillipp},
	date = {2021},
}

@inproceedings{chong_deciding_2021,
	title = {Deciding What's Fair: Challenges of Applying Reinforcement Learning in Online Marketplaces},
	url = {https://openreview.net/forum?id=KB5Kv85Mzg1},
	abstract = {Reinforcement learning ({RL}) techniques offer a versatile and powerful extension to the toolkit for computer scientists and marketplace designers for their use in online marketplaces. As the use of these techniques continues to expand, their application in online marketplaces raise questions of their appropriate use, particularly around issues of fairness and market transparency. I argue that the use of {RL} techniques, alongside similar calls in domains such as automated vehicle systems, is a problem of sociotechnical specification that faces a set of normative and regulatory challenges unique to marketplaces. I provide a selective overview of the {RL} literature as applied to markets to illustrate challenges associated with the use of {RL} techniques in online marketplaces. I conclude with a discussion of capacity-building in research and institutions that is required in order for benefits from algorithmically managed marketplaces to be realized for stakeholders and broader society.},
	eventtitle = {Neural Information Processing Systems},
	booktitle = {Workshop on the Political Economy of Reinforcement Learning Systems},
	author = {Chong, Andrew},
	date = {2021},
}

@inproceedings{chapman_power_2021,
	title = {Power and Accountability in {RL}-driven Environmental Policy},
	url = {https://openreview.net/forum?id=6OnoKEFVD_G},
	abstract = {Machine learning ({ML}) methods already permeate environmental decision-making, from processing high-dimensional data on earth systems to monitoring compliance with environmental regulations. Of the {ML} techniques available to address pressing environmental problems (e.g., climate change, biodiversity loss), Reinforcement Learning ({RL}) may both hold the greatest promise and present the most pressing perils. This paper explores how {RL}-driven policy refracts existing power relations in the environmental domain while also creating unique challenges to ensuring equitable and accountable environmental decision processes. We focus on how {RL} technologies shift the distribution of decision-making, agenda-setting, and ideological power between resource users, governing bodies, and private industry.},
	eventtitle = {Neural Information Processing Systems},
	booktitle = {Workshop on the Political Economy of Reinforcement Learning Systems},
	author = {Chapman, Melissa and Scoville, Caleb and Boettiger, Carl},
	date = {2021},
}

@inproceedings{hu_calculus_2021,
	title = {Calculus of Consent via {MARL}: Legitimating the Collaborative Governance Supplying Public Goods},
	url = {https://openreview.net/forum?id=qNAeKJKftJy},
	abstract = {Public policies that supply public goods, especially those involve collaboration by limiting individual liberty, always give rise to controversies over governance legitimacy. Multi-Agent Reinforcement Learning ({MARL}) methods are appropriate for supporting the legitimacy of the public policies that supply public goods at the cost of individual interests. Among these policies, the inter-regional collaborative pandemic control is a prominent example, which has become much more important for an increasingly inter-connected world facing a global pandemic like {COVID}-19. Different patterns of collaborative strategies have been observed among different systems of regions, yet it lacks an analytical process to reason for the legitimacy of those strategies. In this paper, we use the inter-regional collaboration for pandemic control as an example to demonstrate the necessity of {MARL} in reasoning, and thereby legitimizing policies enforcing such inter-regional collaboration. Experimental results in an exemplary environment show that our {MARL} approach is able to demonstrate the effectiveness and necessity of restrictions on individual liberty for collaborative supply of public goods. Different optimal policies are learned by our {MARL} agents under different collaboration levels, which change in an interpretable pattern of collaboration that helps to balance the losses suffered by regions of different types, and consequently promotes the overall welfare. Meanwhile, policies learned with higher collaboration levels yield higher global rewards, which illustrates the benefit of, and thus provides a novel justification for the legitimacy of, promoting inter-regional collaboration. Therefore, our method shows the capability of {MARL} in computationally modeling and supporting the theory of calculus of consent, developed by Nobel Prize winner J. M. Buchanan.},
	eventtitle = {Neural Information Processing Systems},
	booktitle = {Workshop on the Political Economy of Reinforcement Learning Systems},
	author = {Hu, Yang and Zhu, Zhui and Song, Sirui and Liu, Xue and Yu, Yang},
	date = {2021},
}

@inproceedings{holtman_demanding_2021,
	title = {Demanding and Designing Aligned Cognitive Architectures},
	url = {https://openreview.net/forum?id=bFuvcB4IeQO},
	abstract = {With {AI} systems becoming more powerful and pervasive, there is increasing debate about keeping their actions aligned with the broader goals and needs of humanity.  This multi-disciplinary and multi-stakeholder debate must resolve many issues, here we examine two of them.  The first is to clarify what demands stakeholders might usefully make on the designers of {AI} systems, useful because the technology exists to implement them.  We introduce the framing of cognitive architectures to make this technical topic more accessible.  The second issue is how stakeholders should calibrate their interactions with modern machine learning researchers.  We consider how current fashions in machine learning create a narrative pull that participants in technical and policy discussions should be aware of, so that they can compensate for it.  We identify several technically tractable but currently unfashionable options for improving {AI} alignment.},
	eventtitle = {Neural Information Processing Systems},
	booktitle = {Workshop on the Political Economy of Reinforcement Learning Systems},
	author = {Holtman, Koen},
	date = {2021},
}
